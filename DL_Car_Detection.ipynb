{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f9367d-28d9-4421-bbae-e63ba4884334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Pontus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycocotools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoco\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COCO\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm \n",
    "import json\n",
    "import ipywidgets\n",
    "import nbformat\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "# Created models/functions for pre-processing data\n",
    "from pre_processing import download_coco_datasets as dcd\n",
    "from pre_processing import filter_coco_datasets as fcd\n",
    "from pre_processing import resize_coco_datasets as rcd\n",
    "from pre_processing import resize_annotations as ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9237e8-3d31-43ba-b292-594c64ea8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce3a54-55de-4df3-a3b4-d330788bc343",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067f6f0-a072-40bf-b785-67e1ac80cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize pixel values to range [0,1]\n",
    "def normalize_min_max(image):\n",
    "    return image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7be4c-e105-4b43-a8e2-d0e27e6897b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations_from_json(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    \n",
    "    # Assuming annotations is a list of items to iterate over\n",
    "    for annotation in tqdm(annotations, desc=\"Loading Annotations\"):\n",
    "        # Replace process_annotation with your actual parsing logic\n",
    "        # For example, print each annotation\n",
    "        print(annotation)\n",
    "    \n",
    "    return annotations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4bdc5-35e9-4a22-9043-54bfeb6626cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy loading images\n",
    "class ImageLoader:\n",
    "    def __init__(self, image_directory, annotations_file):\n",
    "        self.image_directory = image_directory\n",
    "        self.annotations_file = annotations_file\n",
    "        self.file_list = [f for f in os.listdir(image_directory) if f.endswith('.jpg') or f.endswith('.jpeg')]\n",
    "        self.num_images = len(self.file_list)\n",
    "        self.annotations = self.load_annotations()\n",
    "\n",
    "    def load_annotations(self):\n",
    "        with open(self.annotations_file, 'r') as f:\n",
    "            annotations_data = json.load(f)\n",
    "        return annotations_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.file_list[idx]\n",
    "        img = cv2.imread(os.path.join(self.image_directory, filename))\n",
    "        # Convert to RGB format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Normalize pixel values\n",
    "        img = normalize_min_max(img)\n",
    "        \n",
    "        # Load corresponding annotation\n",
    "        annotation = self.annotations[filename]\n",
    "        \n",
    "        return img, annotation\n",
    "\n",
    "    def iterate(self):\n",
    "        for idx in tqdm(range(len(self)), desc=\"Loading Images\"):\n",
    "            img, annotation = self.__getitem__(idx)\n",
    "            yield img, annotation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e9839-31e7-42d6-8878-23774123aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to pre-processed data directory\n",
    "pre_processed_data = './coco_datasets/resized_images/'\n",
    "annotations_dir = './coco_datasets/adjusted_annotations/'\n",
    "\n",
    "train_image_loader = ImageLoader(os.path.join(pre_processed_data, 'train2017_resized'), annotations_dir)\n",
    "test_image_loader = ImageLoader(os.path.join(pre_processed_data, 'test2017_resized'), annotations_dir)\n",
    "val_image_loader = ImageLoader(os.path.join(pre_processed_data, 'val2017_resized'), annotations_dir)\n",
    "\n",
    "# Iterate over the image loader to fetch batches of images and annotations\n",
    "for batch_images, batch_annotations in train_image_loader.iterate():\n",
    "    # Process batch of images and annotations as needed\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf71ee-d674-479f-baae-35f5c86c4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 244x244 pixels, 3 channels (RGB)\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 5  # xmin, ymin, xmax, ymax, class\n",
    "\n",
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes))  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399fb93-96b4-4596-a1c4-3547c90d614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model, using adam as optimizer and mean square error as loss function\n",
    "model.compile(optimizer='adam', loss='mse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f26c6b-245b-43dd-8349-e2d67c419938",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff460ac-625e-4106-99ce-a72836b4f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a log directory for visualization logs\n",
    "# tensorboard --logdir logs/fit    # use in command to get url link for logs\n",
    "\n",
    "log_dir = \"logs/fit/\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c89b7f-b145-441f-a1e5-e59743a8c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TQDMCallback(Callback):\n",
    "    def __init__(self, total_epochs):\n",
    "        super(TQDMCallback, self).__init__()\n",
    "        self.total_epochs = total_epochs\n",
    "        self.progress_bar = tqdm(total=self.total_epochs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.progress_bar.update(1)\n",
    "        self.progress_bar.set_description(f\"Epoch {epoch+1}/{self.total_epochs}\")\n",
    "        self.progress_bar.set_postfix(logs)\n",
    "        self.progress_bar.refresh()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00440da6-77ce-4faf-a699-2cbce679de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TQDMCallback\n",
    "tqdm_callback = TQDMCallback(total_epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c38184-1313-4838-a598-41f5cedb272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Define batch size\n",
    "\n",
    "# Create data generators\n",
    "train_generator = data_generator(train_image_loader, train_annotations, batch_size)\n",
    "val_generator = data_generator(val_image_loader, val_annotations, batch_size)\n",
    "\n",
    "\n",
    "# Calculate actual steps per epoch\n",
    "steps_per_epoch = len(train_annotations) // batch_size\n",
    "\n",
    "# Adjust validation steps\n",
    "validation_steps = len(val_annotations) // batch_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c6145-f1c2-4be1-aa7b-2d414f7e3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the generator and print batches of data\n",
    "for batch_images, batch_annotations in train_generator:\n",
    "    print(\"Batch Images:\", batch_images)\n",
    "    print(\"Batch Annotations:\", batch_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4321b64-5706-4b8f-99dd-52eb0114e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with 10 epochs and the data generators\n",
    "model.fit(train_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=validation_steps,\n",
    "          epochs=10,\n",
    "          callbacks=[tqdm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6434e6-94a8-4f9d-ad2c-61d7227b3d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the test data\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9034ead-4636-4c83-906f-51ed2cdc0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save('car_detector_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061cda43-06dd-42e6-b024-6baed090f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('car_detector_model.h5')\n",
    "predictions = loaded_model.predict(new_images) # REMOVE new_images for other data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
